#!/usr/bin/env python3
"""
Demo script showing paper2chunk functionality without requiring a real PDF or API keys.

This demonstrates the core chunking, metadata injection, and output formatting
capabilities using synthetic data.
"""

from paper2chunk.models import Document, DocumentMetadata, Chunk, ChunkMetadata
from paper2chunk.core import SemanticChunker, MetadataInjector
from paper2chunk.config import ChunkingConfig
from paper2chunk.output_formatters import (
    LightRAGFormatter,
    LangChainFormatter,
    MarkdownFormatter
)


def create_demo_document():
    """Create a synthetic document for demonstration"""
    
    # Create document metadata
    metadata = DocumentMetadata(
        title="é‡åŒ–æŠ•èµ„ç ”ç©¶æŠ¥å‘Šï¼šåŠ¨é‡å› å­åˆ†æ",
        author="é‡åŒ–ç ”ç©¶å›¢é˜Ÿ",
        publish_date="2020-01-15",
        source="demo_paper.pdf",
        total_pages=3,
    )
    
    # Create structured content simulating a parsed PDF
    structured_content = [
        {
            "text": "é‡åŒ–æŠ•èµ„ç ”ç©¶æŠ¥å‘Š",
            "page": 1,
            "font_size": 18.0,
            "is_heading": True,
            "level": 1,
        },
        {
            "text": "æœ¬æŠ¥å‘Šåˆ†æäº†åŠ¨é‡å› å­åœ¨ä¸­å›½Aè‚¡å¸‚åœºçš„è¡¨ç°ã€‚",
            "page": 1,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
        {
            "text": "ç¬¬ä¸€ç«  ç ”ç©¶èƒŒæ™¯",
            "page": 1,
            "font_size": 14.0,
            "is_heading": True,
            "level": 2,
        },
        {
            "text": "åŠ¨é‡æ•ˆåº”æ˜¯æŒ‡è‚¡ç¥¨çš„è¿‡å»æ”¶ç›Šç‡èƒ½å¤Ÿé¢„æµ‹æœªæ¥æ”¶ç›Šç‡çš„ç°è±¡ã€‚åœ¨å­¦æœ¯ç•Œå’Œå®åŠ¡ç•Œï¼Œå®ƒè¢«å¹¿æ³›è®¤ä¸ºæ˜¯ä¸€ä¸ªé‡è¦çš„å¸‚åœºå¼‚è±¡ã€‚",
            "page": 1,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
        {
            "text": "æœ¬ç ”ç©¶ç€é‡åˆ†æäº†2015å¹´è‡³2020å¹´æœŸé—´ï¼ŒåŠ¨é‡å› å­åœ¨ä¸­å›½Aè‚¡å¸‚åœºçš„è¡¨ç°ã€‚",
            "page": 1,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
        {
            "text": "ç¬¬äºŒç«  æ•°æ®ä¸æ–¹æ³•",
            "page": 2,
            "font_size": 14.0,
            "is_heading": True,
            "level": 2,
        },
        {
            "text": "2.1 æ•°æ®æ¥æº",
            "page": 2,
            "font_size": 12.0,
            "is_heading": True,
            "level": 3,
        },
        {
            "text": "æœ¬ç ”ç©¶ä½¿ç”¨äº†æ²ªæ·±300æˆåˆ†è‚¡çš„æ—¥é¢‘äº¤æ˜“æ•°æ®ã€‚æ•°æ®æ¥æºäºWindæ•°æ®åº“ï¼Œæ—¶é—´è·¨åº¦ä¸º2015å¹´1æœˆ1æ—¥è‡³2020å¹´12æœˆ31æ—¥ã€‚",
            "page": 2,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
        {
            "text": "2.2 å› å­æ„å»ºæ–¹æ³•",
            "page": 2,
            "font_size": 12.0,
            "is_heading": True,
            "level": 3,
        },
        {
            "text": "åŠ¨é‡å› å­å®šä¹‰ä¸ºè¿‡å»12ä¸ªæœˆçš„ç´¯è®¡æ”¶ç›Šç‡ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒåœ¨æ¯ä¸ªæœˆæœ«è®¡ç®—è‚¡ç¥¨åœ¨è¿‡å»12ä¸ªæœˆçš„æ”¶ç›Šç‡ã€‚",
            "page": 2,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
        {
            "text": "ç¬¬ä¸‰ç«  å®è¯ç»“æœ",
            "page": 3,
            "font_size": 14.0,
            "is_heading": True,
            "level": 2,
        },
        {
            "text": "3.1 å› å­è¡¨ç°",
            "page": 3,
            "font_size": 12.0,
            "is_heading": True,
            "level": 3,
        },
        {
            "text": "å®è¯ç»“æœæ˜¾ç¤ºï¼ŒåŠ¨é‡å› å­åœ¨2020å¹´è¡¨ç°å¾ˆå¥½ï¼Œå¹´åŒ–è¶…é¢æ”¶ç›Šç‡è¾¾åˆ°15%ã€‚è¿™ä¸€ç»“æœè¡¨æ˜åŠ¨é‡æ•ˆåº”åœ¨ä¸­å›½å¸‚åœºä¾ç„¶å­˜åœ¨ã€‚",
            "page": 3,
            "font_size": 11.0,
            "is_heading": False,
            "level": 0,
        },
    ]
    
    # Create document
    document = Document(
        metadata=metadata,
        raw_text="\n".join([item["text"] for item in structured_content]),
        structured_content=structured_content,
        images=[],
    )
    
    return document


def main():
    """Run the demonstration"""
    
    print("=" * 70)
    print("paper2chunk æ¼”ç¤º - PDF to RAG-friendly Chunks")
    print("=" * 70)
    print()
    
    # Step 1: Create demo document
    print("ğŸ“„ Step 1: åˆ›å»ºæ¼”ç¤ºæ–‡æ¡£...")
    document = create_demo_document()
    print(f"   âœ“ æ–‡æ¡£æ ‡é¢˜: {document.metadata.title}")
    print(f"   âœ“ æ€»é¡µæ•°: {document.metadata.total_pages}")
    print(f"   âœ“ æ–‡æœ¬é•¿åº¦: {len(document.raw_text)} å­—ç¬¦")
    print()
    
    # Step 2: Semantic chunking
    print("ğŸ“‘ Step 2: è¯­ä¹‰åˆ†ç‰‡...")
    config = ChunkingConfig(max_chunk_size=300, min_chunk_size=50, overlap_size=30)
    chunker = SemanticChunker(config)
    chunks = chunker.chunk_document(document)
    print(f"   âœ“ ç”Ÿæˆ {len(chunks)} ä¸ªè¯­ä¹‰åˆ†ç‰‡")
    print()
    
    # Step 3: Inject metadata
    print("ğŸ·ï¸  Step 3: æ³¨å…¥å…ƒæ•°æ®...")
    injector = MetadataInjector()
    chunks = injector.inject_metadata(chunks)
    print(f"   âœ“ ä¸ºæ‰€æœ‰åˆ†ç‰‡æ³¨å…¥äº†å…ƒæ•°æ®")
    print()
    
    # Step 4: Display sample chunks
    print("ğŸ“Š Step 4: å±•ç¤ºåˆ†ç‰‡ç¤ºä¾‹...")
    print()
    
    for i, chunk in enumerate(chunks[:2]):  # Show first 2 chunks
        print(f"--- Chunk {i + 1} ---")
        print(f"ç« èŠ‚å±‚çº§: {' â†’ '.join(chunk.metadata.section_hierarchy)}")
        print(f"é¡µç : {chunk.metadata.page_numbers}")
        print(f"å†…å®¹é•¿åº¦: {len(chunk.content)} å­—ç¬¦")
        print()
        print("å¢å¼ºå†…å®¹é¢„è§ˆ:")
        print(chunk.enhanced_content[:300] if chunk.enhanced_content else chunk.content[:300])
        print("...")
        print()
    
    # Step 5: Format outputs
    print("ğŸ’¾ Step 5: ç”Ÿæˆä¸åŒæ ¼å¼çš„è¾“å‡º...")
    print()
    
    # LightRAG format
    lightrag_formatter = LightRAGFormatter()
    lightrag_output = lightrag_formatter.format(chunks)
    print(f"âœ“ LightRAG æ ¼å¼: {len(lightrag_output)} ä¸ªæ¡ç›®")
    print(f"  ç¤ºä¾‹å­—æ®µ: {list(lightrag_output[0].keys())}")
    
    # LangChain format
    langchain_formatter = LangChainFormatter()
    langchain_output = langchain_formatter.format(chunks)
    print(f"âœ“ LangChain æ ¼å¼: {len(langchain_output)} ä¸ªæ¡ç›®")
    print(f"  ç¤ºä¾‹å­—æ®µ: {list(langchain_output[0].keys())}")
    
    # Markdown format
    markdown_formatter = MarkdownFormatter()
    markdown_output = markdown_formatter.format(chunks)
    print(f"âœ“ Markdown æ ¼å¼: {len(markdown_output)} å­—ç¬¦")
    print()
    
    # Step 6: Show output samples
    print("ğŸ“‹ Step 6: è¾“å‡ºæ ¼å¼ç¤ºä¾‹...")
    print()
    
    print("--- LightRAG æ ¼å¼ ---")
    import json
    print(json.dumps(lightrag_output[0], indent=2, ensure_ascii=False)[:500])
    print("...\n")
    
    print("--- Markdown æ ¼å¼ (å‰500å­—ç¬¦) ---")
    print(markdown_output[:500])
    print("...")
    print()
    
    # Summary
    print("=" * 70)
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print("=" * 70)
    print()
    print("æ ¸å¿ƒåŠŸèƒ½å±•ç¤º:")
    print("  âœ“ åŸºäºæ–‡æ¡£ç»“æ„çš„è¯­ä¹‰åˆ†ç‰‡")
    print("  âœ“ è‡ªåŠ¨å…ƒæ•°æ®æ³¨å…¥ï¼ˆæ ‡é¢˜ã€ç« èŠ‚ã€é¡µç ï¼‰")
    print("  âœ“ å¤šç§è¾“å‡ºæ ¼å¼æ”¯æŒï¼ˆLightRAGã€LangChainã€Markdownï¼‰")
    print("  âœ“ åˆ†ç‰‡ç‹¬ç«‹ä¸”è¯­ä¹‰å®Œæ•´")
    print()
    print("åœ¨å®é™…ä½¿ç”¨ä¸­ï¼Œæ‚¨è¿˜å¯ä»¥:")
    print("  â€¢ ä½¿ç”¨ LLM è¿›è¡Œè¯­ä¹‰å¢å¼º")
    print("  â€¢ è‡ªåŠ¨æå–å®ä½“å’Œå…³é”®è¯")
    print("  â€¢ è½¬æ¢å›¾è¡¨ä¸ºæ–‡å­—æè¿°")
    print("  â€¢ å¤„ç†çœŸå®çš„ PDF æ–‡æ¡£")
    print()


if __name__ == "__main__":
    main()
